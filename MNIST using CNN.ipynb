{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7413ef46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801f3ccb1ff94ac2b36dcc9c3af62396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324ce6d9591d4a608713a9d0274968a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329dd0b5e50841a29145ba9182ad4333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5efefda8e2a47bd9e593606a0145403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 98.7699966430664%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Conv2d(1, 16, kernel_size=5, padding=2)\n",
    "        self.layer2 = nn.Conv2d(16, 32, kernel_size=5, padding=2)\n",
    "        self.layer3 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.fc_layer1 = nn.Linear(3*3*64, 300)\n",
    "        self.fc_layer2 = nn.Linear(300, 150)\n",
    "        self.fc_layer3 = nn.Linear(150, 10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #conv layer 1\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        #conv layer2\n",
    "        x = self.layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        #conv layer 3\n",
    "        x = self.layer3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        #fc layer 1\n",
    "        x = x.view(-1,3*3*64)\n",
    "        x = self.fc_layer1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #fc layer 2\n",
    "        x = self.fc_layer2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #fc layer 3\n",
    "        x = self.fc_layer3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "train_data = datasets.MNIST(root=\"./dataset\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_data = datasets.MNIST(root=\"./dataset\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=True)\n",
    "\n",
    "model = CNN_Model()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Model .......\n",
    "\n",
    "for epochs in range(3):\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = images \n",
    "        y = model(x)\n",
    "        loss = criterion(y, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#Testing Model..............\n",
    "        \n",
    "correct = 0\n",
    "total = len(test_data)\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for images, labels in tqdm(test_loader):\n",
    "        x = images  \n",
    "        y = model(x)\n",
    "\n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correct += torch.sum((predictions == labels).float())\n",
    "\n",
    "print(f\"Accuracy= {(correct/total)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1dffab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 cells below this cell are for checking visually how our model performs\n",
    "# add index to load image and label in MNIST test_data\n",
    "# you will get the image and true label corresponding to the image\n",
    "# after running the next cell you will get the label predicted by our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeca3b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true lable: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "im,lb = test_data[5800]\n",
    "im = im.reshape([28,28])\n",
    "plt.imshow(im, cmap='gray')\n",
    "print(\"true lable: {}\".format(lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0abdf60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label: tensor([9])\n"
     ]
    }
   ],
   "source": [
    "x = im.view(1,1,28,28)\n",
    "y = model(x)\n",
    "prediction = torch.argmax(y,dim=1)\n",
    "print(\"predicted label: {}\".format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45acb9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
